# -*- coding: utf-8 -*-
"""breast_cancer_logistic_regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U3puCSCdmfD6MpDwlKOLKAXka-ow19Qy

# Logistic Regression Breast Cancer Case study
"""

# Import libraries
import warnings
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc
from sklearn.preprocessing import StandardScaler
from google.colab import files
uploaded = files.upload()

dts = pd.read_csv('breast_cancer.csv')
print("Dataset Info:")
print(dts.info())
print("\nDataset Description:")
print(dts.describe())

X = dts[['Clump Thickness', 'Uniformity of Cell Size']].values
y = dts['Class'].values  # Target klasifikasi ada pada kolom 'Class'
y = np.reshape(y, (-1,1))

"""## Splitting dataset into training and test set"""

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)

"""## Feature Scalling"""

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""## Training the logistic regression model on Training set"""

warnings.filterwarnings('ignore')
clf = LogisticRegression(random_state=0)
clf.fit(X_train, y_train)

"""## Predicting test set result"""

y_pred = clf.predict(X_test)
print(y_pred)

"""## computing Confusion Matrix and accuracy"""

cm = confusion_matrix(y_test, y_pred)
accu = accuracy_score(y_test, y_pred)
print("\nTest set Accuracy: {:.3f}%".format(accu * 100))

"""## Plot Scatter Plot of Training Data Based On Selected Features"""

plt.figure(figsize=(8, 6))
plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='viridis', edgecolor='k', s=50)
plt.title("Scatter Plot of Training Data (Standardized Clump Thickness vs Uniformity of Cell Size)")
plt.xlabel("Standardized Clump Thickness")
plt.ylabel("Standardized Uniformity of Cell Size")
plt.colorbar(label="Class (2=Benign, 4=Malignant)")
plt.show()

"""## Visualise Confusion Matrix as Heatmap"""

plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="YlGnBu", cbar=False)
plt.title("Confusion Matrix")
plt.xlabel("Predicted Class")
plt.ylabel("Actual Class")
plt.show()

"""## ROC Curve"""

y_train = np.where(y_train == 2, 0, 1)
y_test = np.where(y_test == 2, 0, 1)

y_pred_proba = clf.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc="lower right")
plt.show()

"""## Cross Validation for Accuracy"""

accuracies = cross_val_score(estimator=clf, cv=10, X=X_train, y=y_train)
print("Accuracy: {:.2f} %".format(accuracies.mean()*100))
print("Standard deviation: {:.2f} %".format(accuracies.std()*100))
warnings.filterwarnings('ignore')

"""## Boxplot for Accuracy from Cross Validation"""

plt.figure(figsize=(8, 6))
plt.boxplot(accuracies * 100, vert=False)
plt.title("Accuracy Variation from Cross-Validation")
plt.xlabel("Accuracy (%)")
plt.show()

"""## Grid Search for Best Perameters"""

parameters = [{'penalty': ['l1', 'l2'], 'C':[0.25, 0.5, 0.75, 1], 'solver': ['liblinear', 'saga']}]
grid_search = GridSearchCV(estimator=clf,
                           param_grid=parameters,
                           scoring='accuracy',
                           cv=10,
                           n_jobs=-1)
grid_search.fit(X_train, y_train)
best_accuracy = grid_search.best_score_
best_parameters = grid_search.best_params_
print("Best Accuracy: {:.3f}%".format(best_accuracy * 100))
print("Best Parameters:", best_parameters)
warnings.filterwarnings('ignore')